# Configuration with adaptive loss balancing
# Usage: python -m src.trainer fit --config configs/adaptive.yaml

# experiment_name: null  # Auto-generated
auto_name: true
output_dir: ./experiments

model:
  class_path: src.model.SequentialPINN
  init_args:
    hidden_layers: [64, 64, 64]
    activation: tanh
    num_ffm_frequencies: 2
    exact_bc: true
    learning_rate: 1e-3
    optimizer: adamw
    scheduler: cosine
    loss_weights:
      continuity: 1.0
      poisson: 1.0
      bc: 10.0
    use_adaptive_weights: true
    adaptive_alpha: 0.1  # Smoothing factor: 0.1 = 90% old + 10% new (slow adaptation)
    visualize_on_train_end: true

data:
  batch_size: 4096
  num_points: 20000
  sampler_type: beta
  beta_param: 2.0
  x_range: [0.0, 1.0]
  t_range: [0.0, 1.0]
  val_grid_size: 100

trainer:
  max_epochs: 2000
  accelerator: auto
  devices: 1
  precision: 32
  gradient_clip_val: 1.0
  log_every_n_steps: 10
  check_val_every_n_epoch: 10

use_wandb: false
